# KubeBeaver - environment variables (copy to .env and adjust)
# Usage: cp .env.example .env

# --- Kubernetes (local / Docker Compose) ---
# Path to kubeconfig on host (compose mounts it at /tmp/kubeconfig in backend)
# Example: /Users/your-user/.kube/config or $HOME/.kube/config
KUBECONFIG=

# --- LLM ---
# Provider: groq | openai_compatible
LLM_PROVIDER=openai_compatible

# Groq (when LLM_PROVIDER=groq)
GROQ_API_KEY=
GROQ_MODEL=llama-3.1-8b-instant

# OpenAI-compatible: Ollama, Exo, OpenAI, etc.
# Local: http://localhost:11434/v1
# Backend in Docker + Ollama on host: use host.docker.internal and run Ollama with OLLAMA_HOST=0.0.0.0
OPENAI_BASE_URL=http://host.docker.internal:11434/v1
OPENAI_API_KEY=
OPENAI_MODEL=llama3.2

# --- Limits (optional) ---
REQUEST_TIMEOUT=120
MAX_EVIDENCE_CHARS=60000

# --- In-cluster (only when running inside Kubernetes) ---
# IN_CLUSTER=false

# --- History (backend) ---
# HISTORY_DB_PATH=data/kubebeaver.db
